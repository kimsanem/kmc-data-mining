{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28be1a4",
   "metadata": {},
   "source": [
    "## Prac4: NB, K-NN, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Use Naive bayes, K-nearest, and Decision tree classification algorithms to build classifiers on any two datasets. Pre-process the datasets using techniques specified in Q2. Compare the Accuracy, Precision, Recall and F1 measure reported for each dataset using the abovementioned classifiers under the following situations:\n",
    "    i. Using Holdout method (Random sampling):\n",
    "        a) Training set = 80% Test set = 20%\n",
    "        b) Training set = 66.6% (2/3rd of total), Test set = 33.3%\n",
    "    ii. Using Cross-Validation:\n",
    "        a) 10-fold\n",
    "        b) 5-fold\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6acb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   size (cm)  shape  weight (g)  avg_price (₹)   color  taste     fruit_name\n",
      "0       25.4  round      3089.2          137.1   green  sweet     watermelon\n",
      "1       24.6  round      3283.9          163.8   green  sweet     watermelon\n",
      "2        7.8  round       319.0           91.3   green  sweet  custard apple\n",
      "3       20.0   oval      1607.0           85.7  orange  sweet         papaya\n",
      "4       10.2   long       131.5           37.8  yellow  sweet         banana\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# split model for train and test sets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "# k-nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "fruits = pd.read_csv('fruit_classification_dataset.csv')\n",
    "print(fruits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583fc04a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4972ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   size (cm)  shape  weight (g)  avg_price (₹)  color  taste  fruit_name\n",
      "0       25.4      2      3089.2          137.1      2      1          19\n",
      "1       24.6      2      3283.9          163.8      2      1          19\n",
      "2        7.8      2       319.0           91.3      2      1           5\n",
      "3       20.0      1      1607.0           85.7      3      1          13\n",
      "4       10.2      0       131.5           37.8      7      1           1\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "fruits['shape'] = le.fit_transform(fruits['shape'])\n",
    "fruits['color'] = le.fit_transform(fruits['color'])\n",
    "fruits['taste'] = le.fit_transform(fruits['taste'])\n",
    "fruits['fruit_name'] = le.fit_transform(fruits['fruit_name'])\n",
    "print(fruits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844302f",
   "metadata": {},
   "source": [
    "## k-nn with test size 20% or 1/5 or 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26c27f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['papaya' 'custard apple' 'blueberry' ... 'dragon fruit' 'papaya'\n",
      " 'strawberry']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        apple       1.00      1.00      1.00        84\n",
      "       banana       1.00      1.00      1.00       107\n",
      "    blueberry       1.00      1.00      1.00        91\n",
      "       cherry       1.00      1.00      1.00        97\n",
      "      coconut       0.89      0.88      0.89       106\n",
      "custard apple       1.00      1.00      1.00       106\n",
      " dragon fruit       1.00      1.00      1.00        98\n",
      "        grape       1.00      1.00      1.00       110\n",
      "        guava       1.00      1.00      1.00       100\n",
      "         kiwi       1.00      1.00      1.00       102\n",
      "       lychee       1.00      1.00      1.00       103\n",
      "        mango       0.95      0.99      0.97        99\n",
      "       orange       1.00      1.00      1.00       119\n",
      "       papaya       1.00      1.00      1.00        96\n",
      "         pear       1.00      1.00      1.00        81\n",
      "    pineapple       0.88      0.90      0.89       108\n",
      "         plum       1.00      1.00      1.00        81\n",
      "  pomegranate       0.99      0.96      0.97       115\n",
      "   strawberry       1.00      1.00      1.00        84\n",
      "   watermelon       1.00      1.00      1.00       113\n",
      "\n",
      "     accuracy                           0.98      2000\n",
      "    macro avg       0.99      0.99      0.99      2000\n",
      " weighted avg       0.99      0.98      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take all cols except fruit_name as features for independent variables\n",
    "x = fruits.drop('fruit_name', axis=1)\n",
    "# take fruit_name as target /dependent variable / predictor for classification\n",
    "y = fruits['fruit_name']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=1/5)\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "# print(y_train)\n",
    "# print(y_test)\n",
    "\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_decode = le.inverse_transform(y_pred)\n",
    "y_test_decode = le.inverse_transform(y_test)\n",
    "print(y_pred_decode)\n",
    "print(classification_report(y_test_decode, y_pred_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64848d4f",
   "metadata": {},
   "source": [
    "## nb with test size 20% or 1/5 or 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7023ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['papaya' 'custard apple' 'blueberry' ... 'dragon fruit' 'papaya' 'cherry']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        apple       0.00      0.00      0.00        84\n",
      "       banana       1.00      1.00      1.00       107\n",
      "    blueberry       1.00      1.00      1.00        91\n",
      "       cherry       0.54      1.00      0.70        97\n",
      "      coconut       1.00      1.00      1.00       106\n",
      "custard apple       0.48      1.00      0.65       106\n",
      " dragon fruit       1.00      1.00      1.00        98\n",
      "        grape       1.00      1.00      1.00       110\n",
      "        guava       1.00      1.00      1.00       100\n",
      "         kiwi       0.00      0.00      0.00       102\n",
      "       lychee       1.00      1.00      1.00       103\n",
      "        mango       1.00      1.00      1.00        99\n",
      "       orange       1.00      1.00      1.00       119\n",
      "       papaya       1.00      1.00      1.00        96\n",
      "         pear       1.00      1.00      1.00        81\n",
      "    pineapple       0.51      1.00      0.68       108\n",
      "         plum       1.00      1.00      1.00        81\n",
      "  pomegranate       0.58      1.00      0.73       115\n",
      "   strawberry       0.00      0.00      0.00        84\n",
      "   watermelon       0.00      0.00      0.00       113\n",
      "\n",
      "     accuracy                           0.81      2000\n",
      "    macro avg       0.71      0.80      0.74      2000\n",
      " weighted avg       0.71      0.81      0.74      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "nb = CategoricalNB()\n",
    "categorical_features = ['shape', 'color', 'taste']\n",
    "\n",
    "X_train_cat = X_train[categorical_features]\n",
    "X_test_cat = X_test[categorical_features]\n",
    "\n",
    "nb.fit(X_train_cat, y_train)\n",
    "y_pred_nb = nb.predict(X_test_cat)\n",
    "y_pred_nb_decode = le.inverse_transform(y_pred_nb)\n",
    "y_test_decode = le.inverse_transform(y_test)\n",
    "print(y_pred_nb_decode)\n",
    "print(classification_report(y_test_decode, y_pred_nb_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887ac53",
   "metadata": {},
   "source": [
    "## decision tree with test size 20% or 1/5 or 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb9841ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mango' 'papaya' 'plum' ... 'banana' 'papaya' 'papaya']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        apple       1.00      1.00      1.00       156\n",
      "       banana       1.00      1.00      1.00       148\n",
      "    blueberry       1.00      1.00      1.00       164\n",
      "       cherry       1.00      1.00      1.00       141\n",
      "      coconut       1.00      1.00      1.00       179\n",
      "custard apple       1.00      1.00      1.00       176\n",
      " dragon fruit       1.00      1.00      1.00       165\n",
      "        grape       1.00      1.00      1.00       167\n",
      "        guava       1.00      1.00      1.00       162\n",
      "         kiwi       1.00      1.00      1.00       164\n",
      "       lychee       1.00      1.00      1.00       177\n",
      "        mango       1.00      1.00      1.00       165\n",
      "       orange       1.00      1.00      1.00       165\n",
      "       papaya       1.00      1.00      1.00       173\n",
      "         pear       1.00      1.00      1.00       185\n",
      "    pineapple       1.00      1.00      1.00       186\n",
      "         plum       1.00      1.00      1.00       169\n",
      "  pomegranate       1.00      1.00      1.00       185\n",
      "   strawberry       1.00      1.00      1.00       146\n",
      "   watermelon       1.00      1.00      1.00       161\n",
      "\n",
      "     accuracy                           1.00      3334\n",
      "    macro avg       1.00      1.00      1.00      3334\n",
      " weighted avg       1.00      1.00      1.00      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=None\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_dt_decode = le.inverse_transform(y_pred_dt)\n",
    "print(y_pred_dt_decode)\n",
    "print(classification_report(y_test_decode, y_pred_dt_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66e7db",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d64e56c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5-Fold Accuracy:\n",
      "[0.985  0.9835 0.9855 0.983  0.9865]\n",
      "KNN 10-Fold Accuracy:\n",
      "[0.986 0.987 0.99  0.982 0.986 0.989 0.988 0.989 0.99  0.985]\n",
      "===============================\n",
      "Naive Bayes 5-Fold Accuracy:\n",
      "[ 1.  1.  1. nan  1.]\n",
      "Naive Bayes 10-Fold Accuracy:\n",
      "[ 1.  1.  1.  1.  1.  1.  1. nan  1.  1.]\n",
      "===============================\n",
      "Decision Tree 5-Fold Accuracy:\n",
      "[1. 1. 1. 1. 1.]\n",
      "Decision Tree 10-Fold Accuracy:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 156, in __call__\n",
      "    score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 1538, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 3299 is out of bounds for axis 1 with size 3299\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 156, in __call__\n",
      "    score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 1538, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 3299 is out of bounds for axis 1 with size 3299\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN 5-Fold Accuracy:\")\n",
    "print(cross_val_score(knn, x, y, cv=5))\n",
    "print(\"KNN 10-Fold Accuracy:\")\n",
    "print(cross_val_score(knn, x, y, cv=10))\n",
    "print(\"===============================\")\n",
    "print(\"Naive Bayes 5-Fold Accuracy:\")\n",
    "print(cross_val_score(nb, x, y, cv=5))\n",
    "print(\"Naive Bayes 10-Fold Accuracy:\")\n",
    "print(cross_val_score(nb, x, y, cv=10))\n",
    "print(\"===============================\")\n",
    "print(\"Decision Tree 5-Fold Accuracy:\")\n",
    "print(cross_val_score(dt, x, y, cv=5))\n",
    "print(\"Decision Tree 10-Fold Accuracy:\")\n",
    "print(cross_val_score(dt, x, y, cv=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92931faf",
   "metadata": {},
   "source": [
    "## k-nn with test size 33.33% or 1/3 or 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "667172b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mango' 'papaya' 'plum' ... 'banana' 'papaya' 'papaya']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        apple       1.00      1.00      1.00       156\n",
      "       banana       1.00      1.00      1.00       148\n",
      "    blueberry       1.00      1.00      1.00       164\n",
      "       cherry       1.00      1.00      1.00       141\n",
      "      coconut       0.87      0.83      0.85       179\n",
      "custard apple       1.00      1.00      1.00       176\n",
      " dragon fruit       1.00      1.00      1.00       165\n",
      "        grape       1.00      1.00      1.00       167\n",
      "        guava       0.99      0.99      0.99       162\n",
      "         kiwi       1.00      1.00      1.00       164\n",
      "       lychee       1.00      1.00      1.00       177\n",
      "        mango       0.94      0.92      0.93       165\n",
      "       orange       1.00      1.00      1.00       165\n",
      "       papaya       1.00      1.00      1.00       173\n",
      "         pear       0.99      0.99      0.99       185\n",
      "    pineapple       0.84      0.88      0.86       186\n",
      "         plum       1.00      1.00      1.00       169\n",
      "  pomegranate       0.93      0.95      0.94       185\n",
      "   strawberry       1.00      1.00      1.00       146\n",
      "   watermelon       1.00      1.00      1.00       161\n",
      "\n",
      "     accuracy                           0.98      3334\n",
      "    macro avg       0.98      0.98      0.98      3334\n",
      " weighted avg       0.98      0.98      0.98      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = fruits.drop('fruit_name', axis=1)\n",
    "y = fruits['fruit_name']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=1/3)\n",
    "\n",
    "k = 5\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "y_pred_decode = le.inverse_transform(y_pred)\n",
    "y_test_decode = le.inverse_transform(y_test)\n",
    "print(y_pred_decode)\n",
    "print(classification_report(y_test_decode, y_pred_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273bd790",
   "metadata": {},
   "source": [
    "## nb with test size 33.33% or 1/3 or 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98063757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mango' 'papaya' 'plum' ... 'banana' 'papaya' 'papaya']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        apple       0.00      0.00      0.00       156\n",
      "       banana       1.00      1.00      1.00       148\n",
      "    blueberry       1.00      1.00      1.00       164\n",
      "       cherry       0.49      1.00      0.66       141\n",
      "      coconut       1.00      1.00      1.00       179\n",
      "custard apple       0.52      1.00      0.69       176\n",
      " dragon fruit       1.00      1.00      1.00       165\n",
      "        grape       1.00      1.00      1.00       167\n",
      "        guava       1.00      1.00      1.00       162\n",
      "         kiwi       0.00      0.00      0.00       164\n",
      "       lychee       1.00      1.00      1.00       177\n",
      "        mango       1.00      1.00      1.00       165\n",
      "       orange       1.00      1.00      1.00       165\n",
      "       papaya       1.00      1.00      1.00       173\n",
      "         pear       1.00      1.00      1.00       185\n",
      "    pineapple       0.53      1.00      0.69       186\n",
      "         plum       1.00      1.00      1.00       169\n",
      "  pomegranate       0.54      1.00      0.70       185\n",
      "   strawberry       0.00      0.00      0.00       146\n",
      "   watermelon       0.00      0.00      0.00       161\n",
      "\n",
      "     accuracy                           0.81      3334\n",
      "    macro avg       0.70      0.80      0.74      3334\n",
      " weighted avg       0.71      0.81      0.75      3334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "nb = CategoricalNB()\n",
    "categorical_features = ['shape', 'color', 'taste']\n",
    "X_train_cat = X_train[categorical_features]\n",
    "X_test_cat = X_test[categorical_features]\n",
    "\n",
    "nb.fit(X_train_cat, y_train)\n",
    "y_pred_nb = nb.predict(X_test_cat)\n",
    "y_pred_nb_decode = le.inverse_transform(y_pred_nb)\n",
    "y_test_decode = le.inverse_transform(y_test)\n",
    "print(y_pred_nb_decode)\n",
    "print(classification_report(y_test_decode, y_pred_nb_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a18c7",
   "metadata": {},
   "source": [
    "## decision tree with test size 33.33% or 1/3 or 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3491461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mango' 'papaya' 'plum' ... 'banana' 'papaya' 'papaya']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        apple       1.00      1.00      1.00       156\n",
      "       banana       1.00      1.00      1.00       148\n",
      "    blueberry       1.00      1.00      1.00       164\n",
      "       cherry       1.00      1.00      1.00       141\n",
      "      coconut       1.00      1.00      1.00       179\n",
      "custard apple       1.00      1.00      1.00       176\n",
      " dragon fruit       1.00      1.00      1.00       165\n",
      "        grape       1.00      1.00      1.00       167\n",
      "        guava       1.00      1.00      1.00       162\n",
      "         kiwi       1.00      1.00      1.00       164\n",
      "       lychee       1.00      1.00      1.00       177\n",
      "        mango       1.00      1.00      1.00       165\n",
      "       orange       1.00      1.00      1.00       165\n",
      "       papaya       1.00      1.00      1.00       173\n",
      "         pear       1.00      1.00      1.00       185\n",
      "    pineapple       1.00      1.00      1.00       186\n",
      "         plum       1.00      1.00      1.00       169\n",
      "  pomegranate       1.00      1.00      1.00       185\n",
      "   strawberry       1.00      1.00      1.00       146\n",
      "   watermelon       1.00      1.00      1.00       161\n",
      "\n",
      "     accuracy                           1.00      3334\n",
      "    macro avg       1.00      1.00      1.00      3334\n",
      " weighted avg       1.00      1.00      1.00      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    criterion='entropy', max_depth=5, \n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_dt_decode = le.inverse_transform(y_pred_dt)\n",
    "print(y_pred_dt_decode)\n",
    "print(classification_report(y_test_decode, y_pred_dt_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2039b7",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78af6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5-Fold Accuracy:\n",
      "[0.985  0.9835 0.9855 0.983  0.9865]\n",
      "KNN 10-Fold Accuracy:\n",
      "[0.986 0.987 0.99  0.982 0.986 0.989 0.988 0.989 0.99  0.985]\n",
      "===============================\n",
      "Naive Bayes 5-Fold Accuracy:\n",
      "[ 1.  1.  1. nan  1.]\n",
      "Naive Bayes 10-Fold Accuracy:\n",
      "[ 1.  1.  1.  1.  1.  1.  1. nan  1.  1.]\n",
      "===============================\n",
      "Decision Tree 5-Fold Accuracy:\n",
      "[1. 1. 1. 1. 1.]\n",
      "Decision Tree 10-Fold Accuracy:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 156, in __call__\n",
      "    score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 1538, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 3299 is out of bounds for axis 1 with size 3299\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 156, in __call__\n",
      "    score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/naive_bayes.py\", line 1538, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 3299 is out of bounds for axis 1 with size 3299\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN 5-Fold Accuracy:\")\n",
    "print(cross_val_score(knn, x, y, cv=5))\n",
    "print(\"KNN 10-Fold Accuracy:\")\n",
    "print(cross_val_score(knn, x, y, cv=10))\n",
    "print(\"===============================\")\n",
    "print(\"Naive Bayes 5-Fold Accuracy:\")\n",
    "print(cross_val_score(nb, x, y, cv=5))\n",
    "print(\"Naive Bayes 10-Fold Accuracy:\")\n",
    "print(cross_val_score(nb, x, y, cv=10))\n",
    "print(\"===============================\")\n",
    "print(\"Decision Tree 5-Fold Accuracy:\")\n",
    "print(cross_val_score(dt, x, y, cv=5))\n",
    "print(\"Decision Tree 10-Fold Accuracy:\")\n",
    "print(cross_val_score(dt, x, y, cv=10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
