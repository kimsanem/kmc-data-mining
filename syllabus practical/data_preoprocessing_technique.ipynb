{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dd432b",
   "metadata": {},
   "source": [
    "# Practical 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49d96aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nAim:\\n    Apply data pre-processing techniques such as standardization/normalization, transformation,\\n    aggregation, discretization/binarization, sampling etc. on any dataset\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Aim:\n",
    "    Apply data pre-processing techniques such as standardization/normalization, transformation,\n",
    "    aggregation, discretization/binarization, sampling etc. on any dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8021617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca1e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset: \n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "print(\"Original Dataset: \")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "681bb7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized Sample:\n",
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n"
     ]
    }
   ],
   "source": [
    "# 1. STANDARDIZATION (Z-score normalization: mean=0, SD=1)\n",
    "# ----------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(df[iris.feature_names])\n",
    "\n",
    "print(\"\\nStandardized Sample:\")\n",
    "print(X_std[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c17edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Sample:\n",
      "[[0.22222222 0.625      0.06779661 0.04166667]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.05084746 0.04166667]\n",
      " [0.08333333 0.45833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.66666667 0.06779661 0.04166667]]\n"
     ]
    }
   ],
   "source": [
    "# 2. NORMALIZATION (Min-Max scaling → [0,1])\n",
    "# ----------------------------------------------------------------\n",
    "mms = MinMaxScaler()\n",
    "X_norm = mms.fit_transform(df[iris.feature_names])\n",
    "\n",
    "print(\"\\nNormalized Sample:\")\n",
    "print(X_norm[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02a4d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Sample:\n",
      "[[-0.89568956  1.02290812 -1.3323059  -1.33226632]\n",
      " [-1.18517298 -0.08191725 -1.3323059  -1.33226632]\n",
      " [-1.48792061  0.37512615 -1.38596224 -1.33226632]\n",
      " [-1.64460908  0.14928268 -1.27844068 -1.33226632]\n",
      " [-1.03883758  1.22963765 -1.3323059  -1.33226632]]\n"
     ]
    }
   ],
   "source": [
    "# 3. TRANSFORMATION (Yeo-Johnson for variance stabilization)\n",
    "# ----------------------------------------------------------------\n",
    "pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "X_trans = pt.fit_transform(df[iris.feature_names])\n",
    "\n",
    "print(\"\\nTransformed Sample:\")\n",
    "print(X_trans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c17f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated Features per Class:\n",
      "       sepal length (cm)                  sepal width (cm)                   \\\n",
      "                    mean median       std             mean median       std   \n",
      "target                                                                        \n",
      "0                  5.006    5.0  0.352490            3.428    3.4  0.379064   \n",
      "1                  5.936    5.9  0.516171            2.770    2.8  0.313798   \n",
      "2                  6.588    6.5  0.635880            2.974    3.0  0.322497   \n",
      "\n",
      "       petal length (cm)                  petal width (cm)                   \n",
      "                    mean median       std             mean median       std  \n",
      "target                                                                       \n",
      "0                  1.462   1.50  0.173664            0.246    0.2  0.105386  \n",
      "1                  4.260   4.35  0.469911            1.326    1.3  0.197753  \n",
      "2                  5.552   5.55  0.551895            2.026    2.0  0.274650  \n"
     ]
    }
   ],
   "source": [
    "# 4. AGGREGATION (Summarizing info by target class)\n",
    "# ----------------------------------------------------------------\n",
    "agg = df.groupby(\"target\").agg(['mean', 'median', 'std'])\n",
    "print(\"\\nAggregated Features per Class:\")\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d46ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discretized sample:\n",
      "   sepal length (cm) sepal_length_bin\n",
      "0                5.1                M\n",
      "1                4.9                M\n",
      "2                4.7                M\n",
      "3                4.6                M\n",
      "4                5.0                M\n"
     ]
    }
   ],
   "source": [
    "# 5. DISCRETIZATION (Binning: turning numeric → categories)\n",
    "# ----------------------------------------------------------------\n",
    "bins = [0, 2.5, 4.5, 6.5, 8]\n",
    "labels = ['XS', 'S', 'M', 'L']\n",
    "\n",
    "df[\"sepal_length_bin\"] = pd.cut(df[\"sepal length (cm)\"], bins=bins, labels=labels)\n",
    "\n",
    "print(\"\\nDiscretized sample:\")\n",
    "print(df[[\"sepal length (cm)\", \"sepal_length_bin\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1ac170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After One-Hot Encoding:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  sepal_length_bin_XS  sepal_length_bin_S  sepal_length_bin_M  \\\n",
      "0       0                False               False                True   \n",
      "1       0                False               False                True   \n",
      "2       0                False               False                True   \n",
      "3       0                False               False                True   \n",
      "4       0                False               False                True   \n",
      "\n",
      "   sepal_length_bin_L  sepal_length_bin_nan  \n",
      "0               False                 False  \n",
      "1               False                 False  \n",
      "2               False                 False  \n",
      "3               False                 False  \n",
      "4               False                 False  \n"
     ]
    }
   ],
   "source": [
    "# 6. BINARIZATION (One-Hot Encoding)\n",
    "# ----------------------------------------------------------------\n",
    "df_encoded = pd.get_dummies(df, columns=[\"sepal_length_bin\"], dummy_na=True)\n",
    "\n",
    "print(\"\\nAfter One-Hot Encoding:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1367e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Class Counts:\n",
      "target\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 7. SAMPLING (Making dataset balanced with downsampling)\n",
    "# ----------------------------------------------------------------\n",
    "# Make an intentionally imbalanced dataset for demo\n",
    "df_imbalanced = df[df[\"target\"] != 2]\n",
    "\n",
    "majority = df_imbalanced[df_imbalanced.target == 0]\n",
    "minority = df_imbalanced[df_imbalanced.target == 1]\n",
    "\n",
    "majority_down = resample(majority, \n",
    "                         replace=False,\n",
    "                         n_samples=len(minority),\n",
    "                         random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([majority_down, minority])\n",
    "\n",
    "print(\"\\nBalanced Class Counts:\")\n",
    "print(df_balanced[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4474443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test Split Shapes:\n",
      "X_train: (120, 4)\n",
      "X_test: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# 8. STRATIFIED TRAIN-TEST SPLIT\n",
    "# ---------------------------------------------------------------\n",
    "X = df[iris.feature_names]\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTrain/Test Split Shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
