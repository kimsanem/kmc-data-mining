{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dd432b",
   "metadata": {},
   "source": [
    "# Practical 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Aim:\n",
    "    Apply data pre-processing techniques such as standardization/normalization, transformation,\n",
    "    aggregation, discretization/binarization, sampling etc. on any dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8021617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARDIZATION (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # X: numeric features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c17edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION (min-max to [0,1])\n",
    "mms = MinMaxScaler()\n",
    "X_norm = mms.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMATION (stabilize variance; Box-Cox/yeo-johnson)\n",
    "pt = PowerTransformer(method='yeo-johnson')  # handles zeros and negatives\n",
    "X_trans = pt.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a28101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGGREGATION\n",
    "# Example: aggregate reviews per paper_id -> compute mean score, count reviews\n",
    "agg = df.groupby('paper_id').agg({'score':['mean','median','std','count']})\n",
    "agg.columns = ['_'.join(col).strip() for col in agg.columns.values]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRETIZATION / BINARIZATION\n",
    "# Example: bin scores into classes\n",
    "bins = [0,4,6,8,10]\n",
    "labels = ['poor','average','good','excellent']\n",
    "df['score_bin'] = pd.cut(df['score'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# OR binarize for ML (one-hot)\n",
    "df = pd.get_dummies(df, columns=['score_bin','recommendation'], dummy_na=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLING\n",
    "# Undersample majority class\n",
    "from imblearn.under_sampling import RandomUnderSampler  # optional\n",
    "# OR simple resample:\n",
    "major = df[df.y == 0]\n",
    "minor = df[df.y == 1]\n",
    "major_down = resample(major, replace=False, n_samples=len(minor), random_state=42)\n",
    "df_balanced = pd.concat([major_down, minor])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3350bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATIFIED SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
