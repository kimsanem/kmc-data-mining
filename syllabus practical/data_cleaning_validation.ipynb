{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91153a84",
   "metadata": {},
   "source": [
    "# Practical 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical 1\n",
    "''' \n",
    "Aim:\n",
    "    Apply data cleaning techniques on any dataset (e.g., Paper Reviews dataset in UCI repository).\n",
    "    Techniques may include:\n",
    "    1. handling missing values, \n",
    "    2. outliers and inconsistent values. \n",
    "    3. A set of validation rules can be prepared based on the dataset and validations can be performed.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               paper\n",
      "0  {'id': 1, 'preliminary_decision': 'accept', 'r...\n",
      "1  {'id': 2, 'preliminary_decision': 'accept', 'r...\n",
      "2  {'id': 3, 'preliminary_decision': 'accept', 'r...\n",
      "3  {'id': 4, 'preliminary_decision': 'accept', 'r...\n",
      "4  {'id': 5, 'preliminary_decision': 'accept', 'r...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student-mat.csv\"\n",
    "df = pd.read_csv(url, sep=';')\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9a468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 1)\n",
      "paper    object\n",
      "dtype: object\n",
      "paper    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Basic overview\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c83d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b7595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop exact duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5d1337",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'paper_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'paper_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 4. Validate and fix paper_id\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# If paper_id should be int, attempt conversion; otherwise keep string\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mpaper_id\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpaper_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).str.strip()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# flag suspicious IDs\u001b[39;00m\n\u001b[32m      5\u001b[39m bad_ids = df[df[\u001b[33m'\u001b[39m\u001b[33mpaper_id\u001b[39m\u001b[33m'\u001b[39m].str.len() == \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'paper_id'"
     ]
    }
   ],
   "source": [
    "# 4. Validate and fix paper_id\n",
    "# If paper_id should be int, attempt conversion; otherwise keep string\n",
    "df['paper_id'] = df['paper_id'].astype(str).str.strip()\n",
    "# flag suspicious IDs\n",
    "bad_ids = df[df['paper_id'].str.len() == 0]\n",
    "print(\"Bad paper ids:\", len(bad_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0586e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Parse dates\n",
    "def safe_parse_date(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x, errors='coerce')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df['submission_date'] = df['submission_date'].apply(safe_parse_date)\n",
    "# Rule: submission_date between 1990-01-01 and today\n",
    "mask = (df['submission_date'] < pd.Timestamp('1990-01-01')) | (df['submission_date'] > pd.Timestamp.now())\n",
    "print(\"Out-of-range dates:\", mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Score normalization and missing handling\n",
    "# If score is string like \"8/10\" or \"8.0\", normalize\n",
    "def parse_score(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    s = str(x).strip()\n",
    "    if '/' in s:\n",
    "        a,b = s.split('/')\n",
    "        try:\n",
    "            return float(a)/float(b) * 10  # normalize to scale-10\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['score'] = df['score'].apply(parse_score)\n",
    "# Rule: acceptable scores 0..10 (or your dataset's range)\n",
    "df.loc[(df['score'] < 0) | (df['score'] > 10), 'score'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Recommendation cleanup\n",
    "allowed = {'accept','reject','weak-accept','weak-reject','borderline','revise'}\n",
    "df['recommendation'] = df['recommendation'].astype(str).str.lower().str.strip()\n",
    "df.loc[~df['recommendation'].isin(allowed), 'recommendation'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Text cleaning: trim whitespace and normalize encoding\n",
    "for col in ['title','abstract','review_text','authors']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().replace({'nan': pd.NA})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Missing value strategy (choices)\n",
    "# - If score missing but recommendation present, you might impute score based on recommendation median\n",
    "# - If essential fields (paper_id, reviewer_id) missing -> drop\n",
    "df = df.dropna(subset=['paper_id','reviewer_id'])\n",
    "\n",
    "# Example: impute scores by recommendation median\n",
    "if 'recommendation' in df.columns:\n",
    "    medians = df.groupby('recommendation')['score'].median()\n",
    "    def impute(row):\n",
    "        if pd.isna(row['score']) and pd.notna(row['recommendation']):\n",
    "            return medians.get(row['recommendation'], np.nan)\n",
    "        return row['score']\n",
    "    df['score'] = df.apply(impute, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d440b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Outlier detection for numeric fields (score)\n",
    "# Use IQR method\n",
    "Q1 = df['score'].quantile(0.25)\n",
    "Q3 = df['score'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5*IQR\n",
    "upper = Q3 + 1.5*IQR\n",
    "outliers = df[(df['score'] < lower) | (df['score'] > upper)]\n",
    "print(\"Score outliers:\", len(outliers))\n",
    "\n",
    "# Option: keep outliers but flag them\n",
    "df['score_outlier'] = df['score'].apply(lambda x: x < lower or x > upper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Save cleaned dataset for reproducibility\n",
    "df.to_csv('paper_reviews_cleaned.csv', index=False)\n",
    "print(\"Cleaned saved:\", df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
