{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c29201",
   "metadata": {},
   "source": [
    "# Practical 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nAim:\\n    Run Apriori algorithm to find frequent item sets and association rules on 2 real datasets and use\\n    appropriate evaluation measures to compute correctness of obtained patterns\\n        a) Use minimum support as 50% and minimum confidence as 75%\\n        b) Use minimum support as 60% and minimum confidence as 60 %\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Aim:\n",
    "    Run Apriori algorithm to find frequent item sets and association rules on 2 real datasets and use\n",
    "    appropriate evaluation measures to compute correctness of obtained patterns\n",
    "        a) Use minimum support as 50% and minimum confidence as 75%\n",
    "        b) Use minimum support as 60% and minimum confidence as 60 %\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4feafc1",
   "metadata": {},
   "source": [
    "## Dataset 1: Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "489e546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/heptapod/titanic?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10.8k/10.8k [00:00<00:00, 7.16MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Titanic dataset downloaded at: /Users/kimsan/.cache/kagglehub/datasets/heptapod/titanic/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download Titanic dataset\n",
    "path_titanic = kagglehub.dataset_download(\"heptapod/titanic\")\n",
    "print(\"Titanic dataset downloaded at:\", path_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ff3a0be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:\n",
      "   Passengerid   Age     Fare  Sex  SibSp  zero  zero.1  zero.2  zero.3  \\\n",
      "0            1  22.0   7.2500    0      1     0       0       0       0   \n",
      "1            2  38.0  71.2833    1      1     0       0       0       0   \n",
      "2            3  26.0   7.9250    1      0     0       0       0       0   \n",
      "3            4  35.0  53.1000    1      1     0       0       0       0   \n",
      "4            5  35.0   8.0500    0      0     0       0       0       0   \n",
      "\n",
      "   zero.4  ...  zero.12  zero.13  zero.14  Pclass  zero.15  zero.16  Embarked  \\\n",
      "0       0  ...        0        0        0       3        0        0       2.0   \n",
      "1       0  ...        0        0        0       1        0        0       0.0   \n",
      "2       0  ...        0        0        0       3        0        0       2.0   \n",
      "3       0  ...        0        0        0       1        0        0       2.0   \n",
      "4       0  ...        0        0        0       3        0        0       2.0   \n",
      "\n",
      "   zero.17  zero.18  Survived  \n",
      "0        0        0         0  \n",
      "1        0        0         1  \n",
      "2        0        0         1  \n",
      "3        0        0         1  \n",
      "4        0        0         0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Dataset 1: Groceries\n",
    "df = pd.read_csv('../dataset/titanic.csv')\n",
    "\n",
    "print(\"df:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ce400aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only useful categorical attributes\n",
    "cat_cols = ['Survived','Pclass','Sex','SibSp','Parch','Embarked']\n",
    "df = df[cat_cols].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d439eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric to string so TE can treat as items\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6821058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basket (Titanic):\n",
      "      0    0.0   0.17   0.33   0.42   0.67   0.75   0.83   0.92      1  ...  \\\n",
      "0  True  False  False  False  False  False  False  False  False   True  ...   \n",
      "1  True   True  False  False  False  False  False  False  False   True  ...   \n",
      "2  True  False  False  False  False  False  False  False  False   True  ...   \n",
      "3  True  False  False  False  False  False  False  False  False   True  ...   \n",
      "4  True  False  False  False  False  False  False  False  False  False  ...   \n",
      "\n",
      "     991    992    993    994    995    996    997    998    999    nan  \n",
      "0  False  False  False  False  False  False  False  False  False  False  \n",
      "1  False  False  False  False  False  False  False  False  False  False  \n",
      "2  False  False  False  False  False  False  False  False  False  False  \n",
      "3  False  False  False  False  False  False  False  False  False  False  \n",
      "4  False  False  False  False  False  False  False  False  False  False  \n",
      "\n",
      "[5 rows x 1655 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert each row of features into a transaction list\n",
    "transactions_titanic = df.values.tolist()\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions_titanic).transform(transactions_titanic)\n",
    "basket_titanic = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "print(\"\\nBasket (Titanic):\")\n",
    "print(basket_titanic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c257d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets ≥50% Support (Titanic):\n",
      "    support  itemsets\n",
      "0  1.000000       (0)\n",
      "1  0.627196       (1)\n",
      "2  0.699007     (2.0)\n",
      "3  0.549274       (3)\n",
      "4  0.627196    (0, 1)\n",
      "5  0.699007  (0, 2.0)\n",
      "6  0.549274    (0, 3)\n",
      "\n",
      "Association Rules ≥75% confidence (Titanic):\n",
      "  antecedents consequents   support  confidence  lift\n",
      "0         (1)         (0)  0.627196         1.0   1.0\n",
      "1       (2.0)         (0)  0.699007         1.0   1.0\n",
      "2         (3)         (0)  0.549274         1.0   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/mlxtend/frequent_patterns/association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    }
   ],
   "source": [
    "# ---- A) Support 50%, Confidence 75% ----\n",
    "freq50_t = apriori(basket_titanic, min_support=0.50, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets ≥50% Support (Titanic):\")\n",
    "print(freq50_t)\n",
    "\n",
    "if freq50_t.empty:\n",
    "    print(\"\\nNo frequent itemsets at 50% support (Titanic).\")\n",
    "else:\n",
    "    rules50_t = association_rules(freq50_t, metric=\"confidence\", min_threshold=0.75)\n",
    "    print(\"\\nAssociation Rules ≥75% confidence (Titanic):\")\n",
    "    print(rules50_t[['antecedents','consequents','support','confidence','lift']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c57a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets ≥60% Support (Titanic):\n",
      "    support  itemsets\n",
      "0  1.000000       (0)\n",
      "1  0.627196       (1)\n",
      "2  0.699007     (2.0)\n",
      "3  0.627196    (0, 1)\n",
      "4  0.699007  (0, 2.0)\n",
      "\n",
      "Association Rules ≥60% confidence (Titanic):\n",
      "  antecedents consequents   support  confidence  lift\n",
      "0         (0)         (1)  0.627196    0.627196   1.0\n",
      "1         (1)         (0)  0.627196    1.000000   1.0\n",
      "2         (0)       (2.0)  0.699007    0.699007   1.0\n",
      "3       (2.0)         (0)  0.699007    1.000000   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/mlxtend/frequent_patterns/association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    }
   ],
   "source": [
    "# ---- B) Support 60%, Confidence 60% ----\n",
    "freq60_t = apriori(basket_titanic, min_support=0.60, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets ≥60% Support (Titanic):\")\n",
    "print(freq60_t)\n",
    "\n",
    "if freq60_t.empty:\n",
    "    print(\"\\nNo frequent itemsets at 60% support (Titanic).\")\n",
    "else:\n",
    "    rules60_t = association_rules(freq60_t, metric=\"confidence\", min_threshold=0.60)\n",
    "    print(\"\\nAssociation Rules ≥60% confidence (Titanic):\")\n",
    "    print(rules60_t[['antecedents','consequents','support','confidence','lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb41fc",
   "metadata": {},
   "source": [
    "## Dataset 2: Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2e2c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/kimsan/.cache/kagglehub/datasets/uciml/mushroom-classification/versions/1\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"uciml/mushroom-classification\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ca9db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1: \n",
      "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
      "0     p         x           s         n       t    p               f   \n",
      "1     e         x           s         y       t    a               f   \n",
      "2     e         b           s         w       t    l               f   \n",
      "3     p         x           y         w       t    p               f   \n",
      "4     e         x           s         g       f    n               f   \n",
      "\n",
      "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "2            c         b          n  ...                        s   \n",
      "3            c         n          n  ...                        s   \n",
      "4            w         b          k  ...                        s   \n",
      "\n",
      "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring-number ring-type spore-print-color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../dataset/mushrooms.csv')\n",
    "print(\"df1: \")\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbca1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row to transactions\n",
    "transactions = df1.astype(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8fb31510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row to transactions\n",
    "transactions = df1.astype(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7d7ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions).transform(transactions)\n",
    "basket_mush = pd.DataFrame(te_data, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0281c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemsets ≥50% support:\n",
      "       support                     itemsets\n",
      "0     0.947070                          (b)\n",
      "1     0.855244                          (c)\n",
      "2     0.964549                          (e)\n",
      "3     1.000000                          (f)\n",
      "4     0.520926                          (g)\n",
      "...        ...                          ...\n",
      "1314  0.611521     (n, e, f, s, t, o, w, p)\n",
      "1315  0.505416  (n, e, f, b, s, o, w, c, p)\n",
      "1316  0.516987  (n, e, f, b, s, t, w, c, p)\n",
      "1317  0.580010  (n, e, f, b, s, o, t, w, p)\n",
      "1318  0.511078  (n, e, f, s, t, o, w, c, p)\n",
      "\n",
      "[1319 rows x 2 columns]\n",
      "Rules ≥75% confidence:\n",
      "      antecedents            consequents   support  confidence      lift\n",
      "0             (b)                    (c)  0.802314    0.847154  0.990541\n",
      "1             (c)                    (b)  0.802314    0.938112  0.990541\n",
      "2             (e)                    (b)  0.911620    0.945125  0.997946\n",
      "3             (b)                    (e)  0.911620    0.962568  0.997946\n",
      "4             (f)                    (b)  0.947070    0.947070  1.000000\n",
      "...           ...                    ...       ...         ...       ...\n",
      "35177   (t, c, o)     (n, e, s, f, w, p)  0.511078    0.881154  1.210433\n",
      "35178   (t, c, w)     (n, e, s, f, o, p)  0.511078    0.826433  1.213656\n",
      "35179   (p, t, c)     (n, e, s, f, o, w)  0.511078    0.826433  1.257293\n",
      "35180      (s, c)  (n, t, e, f, o, w, p)  0.511078    0.766334  1.206531\n",
      "35181      (t, c)  (n, e, s, f, o, w, p)  0.511078    0.826433  1.257293\n",
      "\n",
      "[35182 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/mlxtend/frequent_patterns/association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# A) support 50%, confidence 75%\n",
    "freq_50 = apriori(basket_mush, min_support=0.50, use_colnames=True)\n",
    "rules_50 = association_rules(freq_50, metric=\"confidence\", min_threshold=0.75)\n",
    "\n",
    "print(\"Itemsets ≥50% support:\")\n",
    "print(freq_50)\n",
    "\n",
    "print(\"Rules ≥75% confidence:\")\n",
    "print(rules_50[['antecedents','consequents','support','confidence','lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1449cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemsets ≥60% support:\n",
      "      support                  itemsets\n",
      "0    0.947070                       (b)\n",
      "1    0.855244                       (c)\n",
      "2    0.964549                       (e)\n",
      "3    1.000000                       (f)\n",
      "4    0.646972                       (k)\n",
      "..        ...                       ...\n",
      "694  0.613737  (n, e, f, b, o, w, c, p)\n",
      "695  0.608075  (n, e, f, b, s, o, w, p)\n",
      "696  0.603644  (n, e, f, b, t, o, w, p)\n",
      "697  0.650665  (n, e, f, b, s, t, w, p)\n",
      "698  0.611521  (n, e, f, s, t, o, w, p)\n",
      "\n",
      "[699 rows x 2 columns]\n",
      "Rules ≥60% confidence:\n",
      "      antecedents            consequents   support  confidence      lift\n",
      "0             (b)                    (c)  0.802314    0.847154  0.990541\n",
      "1             (c)                    (b)  0.802314    0.938112  0.990541\n",
      "2             (e)                    (b)  0.911620    0.945125  0.997946\n",
      "3             (b)                    (e)  0.911620    0.962568  0.997946\n",
      "4             (f)                    (b)  0.947070    0.947070  1.000000\n",
      "...           ...                    ...       ...         ...       ...\n",
      "20727         (s)  (n, e, f, t, o, w, p)  0.611521    0.761730  1.199281\n",
      "20728         (t)  (n, e, f, s, o, w, p)  0.611521    0.804404  1.223779\n",
      "20729         (o)  (n, e, f, s, t, w, p)  0.611521    0.663462  0.972566\n",
      "20730         (w)  (n, e, f, s, t, o, p)  0.611521    0.626324  1.024206\n",
      "20731         (p)  (n, e, f, s, t, o, w)  0.611521    0.611521  1.000000\n",
      "\n",
      "[20732 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsan/miniconda3/envs/ml/lib/python3.12/site-packages/mlxtend/frequent_patterns/association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    }
   ],
   "source": [
    "# B) support 60%, confidence 60%\n",
    "freq_60 = apriori(basket_mush, min_support=0.60, use_colnames=True)\n",
    "rules_60 = association_rules(freq_60, metric=\"confidence\", min_threshold=0.60)\n",
    "\n",
    "print(\"Itemsets ≥60% support:\")\n",
    "print(freq_60)\n",
    "\n",
    "print(\"Rules ≥60% confidence:\")\n",
    "print(rules_60[['antecedents','consequents','support','confidence','lift']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
