{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f0c194",
   "metadata": {},
   "source": [
    "# Practical 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b918153",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Aim:\n",
    "    Use Naive bayes, K-nearest, and Decision tree classification algorithms to build classifiers on\n",
    "    any two datasets. Pre-process the datasets using techniques specified in Q2. Compare the\n",
    "    Accuracy, Precision, Recall and F1 measure reported for each dataset using the above mentioned\n",
    "    classifiers under the following situations:\n",
    "        i. Using Holdout method (Random sampling):\n",
    "            a) Training set = 80% Test set = 20%\n",
    "            b) Training set = 66.6% (2/3rd of total), Test set = 33.3%\n",
    "        ii. Using Cross-Validation:\n",
    "            a) 10-fold\n",
    "            b) 5-fold\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73b2244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ee108",
   "metadata": {},
   "source": [
    "## Dataset 1: Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de39aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y_iris = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_iris_scaled = scaler.fit_transform(X_iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7287d25",
   "metadata": {},
   "source": [
    "## Dataset 2: Titanic (Clean Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9b465df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df_titan = pd.read_csv(\"../dataset/titanic.csv\")\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = X_titan.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = X_titan.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "\n",
    "# Numeric pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encode\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "ct = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "X_titan_pre = ct.fit_transform(X_titan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "306677a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45cb5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluate model \n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_test, preds),\n",
    "        \"Precision\": precision_score(y_test, preds, average=\"macro\"),\n",
    "        \"Recall\": recall_score(y_test, preds, average=\"macro\"),\n",
    "        \"F1\": f1_score(y_test, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90d2ab",
   "metadata": {},
   "source": [
    "### 1. HOLDOUT METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee297237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_holdout(X, y, test_size, label):\n",
    "    print(f\"\\n--- Holdout ({label}) ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    for name, model in models.items():\n",
    "        results = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "        print(f\"{name} → {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1977b366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Holdout (Iris 80/20) ---\n",
      "Naive Bayes → {'Accuracy': 0.9666666666666667, 'Precision': 0.9696969696969697, 'Recall': 0.9666666666666667, 'F1': 0.9665831244778612}\n",
      "KNN (k=5) → {'Accuracy': 0.9333333333333333, 'Precision': 0.9444444444444445, 'Recall': 0.9333333333333332, 'F1': 0.9326599326599326}\n",
      "Decision Tree → {'Accuracy': 0.9333333333333333, 'Precision': 0.9333333333333332, 'Recall': 0.9333333333333332, 'F1': 0.9333333333333332}\n",
      "\n",
      "--- Holdout (Titanic 80/20) ---\n",
      "Naive Bayes → {'Accuracy': 0.8053435114503816, 'Precision': 0.7471085586663475, 'Recall': 0.7348392965433597, 'F1': 0.7404580152671756}\n",
      "KNN (k=5) → {'Accuracy': 0.8587786259541985, 'Precision': 0.8305226174791392, 'Recall': 0.7852486355366889, 'F1': 0.8034588325933134}\n",
      "Decision Tree → {'Accuracy': 0.8358778625954199, 'Precision': 0.7868733256792958, 'Recall': 0.784111582777441, 'F1': 0.7854708178615634}\n"
     ]
    }
   ],
   "source": [
    "# 80% Train — 20% Test\n",
    "# for iris dataset\n",
    "run_holdout(X_iris_scaled, y_iris, 0.2, \"Iris 80/20\")\n",
    "\n",
    "# for titanic dataset\n",
    "run_holdout(X_titan_pre, y_titan, 0.2, \"Titanic 80/20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e78c6a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Holdout (Iris 66/33) ---\n",
      "Naive Bayes → {'Accuracy': 0.92, 'Precision': 0.9251461988304094, 'Recall': 0.9215686274509803, 'F1': 0.9212962962962963}\n",
      "KNN (k=5) → {'Accuracy': 0.92, 'Precision': 0.9365079365079364, 'Recall': 0.9215686274509803, 'F1': 0.92046783625731}\n",
      "Decision Tree → {'Accuracy': 0.94, 'Precision': 0.9500000000000001, 'Recall': 0.9411764705882352, 'F1': 0.9407149084568439}\n",
      "\n",
      "--- Holdout (Titanic 66/33) ---\n",
      "Naive Bayes → {'Accuracy': 0.8004587155963303, 'Precision': 0.7417781614156236, 'Recall': 0.7289146779993463, 'F1': 0.7347542427993035}\n",
      "KNN (k=5) → {'Accuracy': 0.8440366972477065, 'Precision': 0.8151495016611296, 'Recall': 0.7584177835894084, 'F1': 0.7794047619047619}\n",
      "Decision Tree → {'Accuracy': 0.8555045871559633, 'Precision': 0.8209243773041992, 'Recall': 0.791680287675711, 'F1': 0.8043129795464745}\n"
     ]
    }
   ],
   "source": [
    "# 66.6% Train — 33.3% Test\n",
    "run_holdout(X_iris_scaled, y_iris, 0.333, \"Iris 66/33\")\n",
    "run_holdout(X_titan_pre, y_titan, 0.333, \"Titanic 66/33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa961aa4",
   "metadata": {},
   "source": [
    "### 2. CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9e3d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(X, y, folds, label):\n",
    "    print(f\"\\n--- {folds}-Fold Cross Validation ({label}) ---\")\n",
    "    for name, model in models.items():\n",
    "        cv = cross_validate(model, X, y, cv=folds,\n",
    "                            scoring=[\"accuracy\",\"precision_macro\",\"recall_macro\",\"f1_macro\"])\n",
    "        print(f\"{name} → \"\n",
    "              f\"Acc: {cv['test_accuracy'].mean():.3f}, \"\n",
    "              f\"Prec: {cv['test_precision_macro'].mean():.3f}, \"\n",
    "              f\"Rec: {cv['test_recall_macro'].mean():.3f}, \"\n",
    "              f\"F1: {cv['test_f1_macro'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc5c4cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 10-Fold Cross Validation (Iris) ---\n",
      "Naive Bayes → Acc: 0.953, Prec: 0.963, Rec: 0.953, F1: 0.952\n",
      "KNN (k=5) → Acc: 0.953, Prec: 0.960, Rec: 0.953, F1: 0.953\n",
      "Decision Tree → Acc: 0.953, Prec: 0.959, Rec: 0.953, F1: 0.953\n",
      "\n",
      "--- 10-Fold Cross Validation (Titanic) ---\n",
      "Naive Bayes → Acc: 0.819, Prec: 0.783, Rec: 0.743, F1: 0.747\n",
      "KNN (k=5) → Acc: 0.802, Prec: 0.771, Rec: 0.735, F1: 0.736\n",
      "Decision Tree → Acc: 0.614, Prec: 0.671, Rec: 0.599, F1: 0.561\n"
     ]
    }
   ],
   "source": [
    "# 10-Fold Cross Validation\n",
    "run_cv(X_iris_scaled, y_iris, 10, \"Iris\")\n",
    "run_cv(X_titan_pre, y_titan, 10, \"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0abddfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5-Fold Cross Validation (Iris) ---\n",
      "Naive Bayes → Acc: 0.953, Prec: 0.958, Rec: 0.953, F1: 0.953\n",
      "KNN (k=5) → Acc: 0.960, Prec: 0.963, Rec: 0.960, F1: 0.960\n",
      "Decision Tree → Acc: 0.953, Prec: 0.955, Rec: 0.953, F1: 0.953\n",
      "\n",
      "--- 5-Fold Cross Validation (Titanic) ---\n",
      "Naive Bayes → Acc: 0.801, Prec: 0.774, Rec: 0.728, F1: 0.725\n",
      "KNN (k=5) → Acc: 0.776, Prec: 0.753, Rec: 0.727, F1: 0.716\n",
      "Decision Tree → Acc: 0.434, Prec: 0.559, Rec: 0.432, F1: 0.350\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold Cross Validation\n",
    "run_cv(X_iris_scaled, y_iris, 5, \"Iris\")\n",
    "run_cv(X_titan_pre, y_titan, 5, \"Titanic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
